{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "    # Oefeningen\n",
    "\n",
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laad de dataset in. Bekijk deze even om te zien waar je juist mee gaan werken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split de dataset. We gebruiken in deze les consequent random seed 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gebruik een standardscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CreÃ«er en train een SVM classifier. Gebruik random seed 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak voorspellingen over de test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereken de accuraatheidscore van je model\n",
    "\n",
    "\n",
    "# Laat een classification report genereren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even opfrissen:\n",
    "- *Precision*: (aantal True Positives) / (aantal True Positives + aantal False Positives)\n",
    "- *Recall*: (aantal True Positives) / (aantal True Positives + aantal False Negatives)\n",
    "- *Accuracy*: (aantal True Positive + aantal True Negative) / (totaal aantal Positive + totaal aantal Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra oefening: je kan nog finetunen met de hyperparameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits\n",
    "\n",
    "Experimenteer met verschillende kernels, C-waardes, en kies een optimale configuratie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digits dataset:\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# laad de data in goede variabelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizeren, doe dit eens in een pipeline samen met je model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak voorspellingen op de test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bereken accuraatheid en classificatie report. Welk cijfers is het moeilijkst om te classificeren ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de volgende opgave mag je de hulp van ChatGPT en dergelijke inroepen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak een plot van de eerste 9 testcases, waarbij je het echte label in de titel vergelijk met het voorspelde label.\n",
    "# de bedoeling is dat je zo zelf visueel kan checken of de classifier het voor de specifieke items juist had.\n",
    "# pas je code aan zodat er enkel testcases worden getoond die fout werden geclassificeerd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wijn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train een SVM-classificator op de Wine-dataset, die je kunt laden met 'sklearn.datasets.load_wine()'. Deze dataset bevat de chemische analyse van 178 wijnmonsters geproduceerd door 3 verschillende telers: het doel is om een classificatiemodel te trainen dat in staat is om de cultivator te voorspellen op basis van de chemische analyse van de wijn. Aangezien SVM-classifiers binaire classifiers zijn, moet je one-versus-all gebruiken om alle 3 klassen te classificeren. Welke nauwkeurigheid kan je bereiken?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stappenplan:\n",
    "1. Data inladen\n",
    "2. Train/test split\n",
    "3. Een lineaire SVM gebruiken\n",
    "4. Een lineaire SVM gebruiken met 1000000 iteraties\n",
    "5. Evalueren\n",
    "6. Oplossingen zoeken voor mogelijke problemen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineaire SVM gebruiken\n",
    "# Het probleem met meerdere klasses oplossen - bekijk de decoumentatie van LinearSVM op scikit learn docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gebruik 1000000 iteraties\n",
    "# wat is nu je conclusie over de dataset ? Hoe kun je dit oplossen ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoek op de documentatie op hoe je de cross_val_score kan gebruiken om cross-validatie te doen\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu kijken we naar andere kernels voor algemene SVM\n",
    "\n",
    "We werken verder met dezelfde dataset, maar nu niet meer beperkt tot een lineaire SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline # ter illustratie, make_pipeline heeft lichtjes andersyntax dan met Pipeline werken\n",
    "svm_clf = make_pipeline(StandardScaler(), SVC(random_state=10))\n",
    "cross_val_score(svm_clf, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan ze zoeken naar optimizatie van parameters. Dit moet ik ook nog introduceren in de theorieles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimaliseer de parameters met CVGrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergelijk nu de best_score_component van de CVGridSearch met de de score die dit model haalt op de test set. Er zit een verschil op. Wat is er gebeurt ? Hoe hadden we dit moeten oplossen ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressie met een SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gegeven een dataset, kan je regressie doen in plaats van classificatie. De algoritmes werken bijna hetzelfde, met volgende cruciaal verschil:\n",
    "- de classifier wil zoveel mogelijk instances *buiten* de straat zetten.\n",
    "- de regressor wil zoveel mogelijk instances *binnen* de straat zetten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschouw volgende dataset die je wil benaderen met een regressiemodel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR # de R in SVR is van regressor, de C in SVC van classifier\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# code om een kwadratische dataset te genereren\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(50, 1) - 1\n",
    "y = 0.2 + 0.1 * X[:, 0] + 0.5 * X[:, 0] ** 2 + np.random.randn(50) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak een pipeline van een standaardscaler en de voor hand liggende SVR voor dit probleem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met volgende code kun je bekijken wat het model heeft bereikt (ter illustratie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_support_vectors(svm_reg, X, y):\n",
    "    y_pred = svm_reg.predict(X)\n",
    "    epsilon = svm_reg[-1].epsilon\n",
    "    off_margin = np.abs(y - y_pred) >= epsilon\n",
    "    return np.argwhere(off_margin)\n",
    "\n",
    "def plot_svm_regression(svm_reg, X, y, axes):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100).reshape(100, 1)\n",
    "    y_pred = svm_reg.predict(x1s)\n",
    "    epsilon = svm_reg[-1].epsilon\n",
    "    plt.plot(x1s, y_pred, \"k-\", linewidth=2, label=r\"$\\hat{y}$\", zorder=-2)\n",
    "    plt.plot(x1s, y_pred + epsilon, \"k--\", zorder=-2)\n",
    "    plt.plot(x1s, y_pred - epsilon, \"k--\", zorder=-2)\n",
    "    plt.scatter(X[svm_reg._support], y[svm_reg._support], s=180,\n",
    "                facecolors='#AAA', zorder=-1)\n",
    "    plt.plot(X, y, \"bo\")\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.axis(axes)\n",
    "\n",
    "svm_poly_reg._support = find_support_vectors(svm_poly_reg, X, y)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, figsize=(9, 4), sharey=True)\n",
    "plt.sca(axes)\n",
    "plot_svm_regression(svm_poly_reg, X, y, [-1, 1, 0, 1])\n",
    "plt.title(f\"degree={svm_poly_reg[-1].degree}, \"\n",
    "          f\"C={svm_poly_reg[-1].C}, \"\n",
    "          f\"epsilon={svm_poly_reg[-1].epsilon}\")\n",
    "plt.ylabel(\"$y$\", rotation=0)\n",
    "plt.grid()\n",
    "\n",
    "save_fig(\"svm_with_polynomial_kernel_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenteer met andere kernels en hperparameters of je betere resultaten kan bekomen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_algorithms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
