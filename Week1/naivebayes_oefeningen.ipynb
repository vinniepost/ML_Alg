{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We beginnen met een simpele bayes functies die gegeven een aantal conditionele kansen en de algemene kans van een binair label, de kans gaat berekenen op een label gegeven de geziene data. Dit is puur de formule van Bayes invullen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998928686212193\n"
     ]
    }
   ],
   "source": [
    "def bayes(conditional_prob_label, conditional_other_label_prob, prob_of_event):\n",
    "    #TODO: een hoop factoren met elkaar vermenigvuldigen\n",
    "    numerator = conditional_prob_label * prob_of_event\n",
    "    denominator = numerator + (conditional_other_label_prob * (1 - prob_of_event))\n",
    "    return (numerator / denominator)\n",
    "\n",
    "spam_given_money = bayes(0.4, 0.0001, 0.7)\n",
    "print(spam_given_money)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor de classificatie, moet je de noemer zelfs niet uitrekenen. De classifier zoekt de grootste teller en geeft dat terug als antwoord. We kijken nu naar een classificatie met meerdere woorden (realistischer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.1\n",
      "0.001\n",
      "0.99999\n",
      "0.05\n",
      "0.3\n",
      "Is Spam: HAM\n"
     ]
    }
   ],
   "source": [
    "given_money = [0.4, 0.00001]\n",
    "uganda = [0.1, 0.05]\n",
    "ap_hogeschool = [0.001, 0.3]\n",
    "conditional_data = [given_money, uganda, ap_hogeschool]\n",
    "prob_spam = 0.45\n",
    "data_vector = [0, 1, 1] # uganda en AP Hogeschool, geen 'moneytransfer'\n",
    "\n",
    "def bayes_classifier_spam(conditional_data, prob_spam, data_vector):\n",
    "\n",
    "    #checken voor SPAM:\n",
    "    spam_probability = prob_spam\n",
    "    for i in range(len(conditional_data)):\n",
    "        if data_vector[i] == 1:\n",
    "            print(conditional_data[i][0]) #debugging\n",
    "            spam_probability *= conditional_data[i][0]\n",
    "        else:\n",
    "            print((1 - conditional_data[i][0])) #debugging\n",
    "            spam_probability *= (1 - conditional_data[i][0])\n",
    "    \n",
    "    #checken voor HAM:\n",
    "    not_spam_probability = 1-prob_spam\n",
    "    for i in range(len(conditional_data)):\n",
    "        if data_vector[i] == 1:\n",
    "            print(conditional_data[i][1]) #debugging\n",
    "            not_spam_probability *= conditional_data[i][1]\n",
    "        else:\n",
    "            print((1 - conditional_data[i][1])) #debugging\n",
    "            not_spam_probability *= (1 - conditional_data[i][1])\n",
    "\n",
    "    if (spam_probability > not_spam_probability):\n",
    "        return \"SPAM\"\n",
    "    else:\n",
    "        return \"HAM\"\n",
    "\n",
    "is_spam = bayes_classifier_spam(conditional_data, prob_spam, data_vector)\n",
    "print(\"Is Spam:\", is_spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "We maken nu een volledige classifier aan, die we ook kunnen hertrainen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesianClassifier:\n",
    "    def __init__(self):\n",
    "        self.labels = ['spam', 'ham', 'ongekend']\n",
    "        self.label_probabilities = {label: 1/3 for label in self.labels}\n",
    "        self.feature_probabilities = {label: {} for label in self.labels} # de kansen zijn initieel ongekend!\n",
    "    \n",
    "    def train(self, label, feature_probabilities):\n",
    "        #todo: trainen is gelabelde data toevoegen en kansen updaten op basis van de nieuwe info\n",
    "        \n",
    "\n",
    "        return None\n",
    "    \n",
    "    def classify(self, features):\n",
    "        #todo: klassificeren is SPAM, HAM of ONGEKEND teruggeven\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "classifier = NaiveBayesianClassifier()\n",
    "\n",
    "# Training data\n",
    "training_data = {\n",
    "    'spam': {'word1': [0.9, 0.2, 0.8], 'word2': [0.8, 0.1, 0.3]},\n",
    "    'ham': {'word1': [0.1, 0.8, 0.2], 'word2': [0.2, 0.9, 0.7]},\n",
    "    'ongekend': {'word1': [0.5, 0.4, 0.6], 'word2': [0.4, 0.5, 0.4]}\n",
    "}\n",
    "\n",
    "for label, data in training_data.items():\n",
    "    for feature, probabilities in data.items():\n",
    "        classifier.train(label, {feature: p for p in probabilities}) \n",
    "\n",
    "# Classificatie\n",
    "input_features = {'word1': 0, 'word2': 1}\n",
    "result = classifier.classify(input_features)\n",
    "print(\"Geklassificeerd als:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_algorithms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
